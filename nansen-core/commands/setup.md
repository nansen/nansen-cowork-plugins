---
description: Set up the Nansen intelligence ecosystem for a new team member
allowed-tools: Read, Write, Edit, Bash(ls:*), Bash(mkdir:*), Bash(cp:*), Bash(find:*), Bash(test:*), Bash(cat:*), Bash(echo:*), Bash(date:*), Bash(python3:*), Bash(npm:*), Bash(node:*), Bash(wc:*), slack_search_public, slack_search_public_and_private, slack_read_channel, slack_read_thread, slack_search_channels, slack_search_users, list_meetings, get_transcript, get_meeting_details, create_scheduled_task
---

Walk the user through setting up Nansen's intelligence ecosystem on their machine. Follow these steps in order, checking status at each stage before moving on. Be conversational and helpful -- the user may not be technical. Use clear language and explain what each step does and why.

## Step 1 -- Check folder access

Check if a workspace folder is currently connected by listing the contents of the mounted directory. Look for a `nansen` directory or the nansen-core plugin folder.

If no folder is connected:
- Tell the user: "First, I need access to your Nansen workspace folder. Click the folder icon in the sidebar and select the folder where you keep your Nansen work (or where you'd like to set one up)."
- Wait for them to confirm, then re-check.

If a folder IS connected, check what already exists. Look for:
- `nansen/sources/` directory
- `nansen/intelligence/` directory
- `nansen/outputs/` directory
- `.nansen-config.json` file

Report what you find. If everything exists and the config file is present, ask if they want to re-run setup or if they're all set.

## Step 2 -- Create folder structure

Create the three core directories if they don't already exist:

```
nansen/
├── sources/          # Raw input files (PDFs, transcripts, notes)
├── intelligence/     # Extracted knowledge (synced to Google Drive)
└── outputs/          # Generated deliverables (reports, docs, analysis)
```

For each directory, create it and add a brief README.md inside explaining its purpose:

**sources/README.md**: "This folder holds your raw source material - meeting transcripts from Fathom, PDFs, research documents, email exports, and notes. Drop files here and use the Market Research skill to extract intelligence from them."

**intelligence/README.md**: "This is the team knowledge base. Intelligence files here are synced to Google Drive so everyone on the team can access them. Don't edit these manually - they're generated by extraction skills and follow a specific format (YAML frontmatter + markdown)."

**outputs/README.md**: "This folder holds deliverables generated from intelligence - client reports, analysis documents, presentations, and other outputs. These stay local to your machine."

After creating, confirm: "Your folder structure is ready. Here's what I set up: [list the three folders with a brief description of each]."

## Step 3 -- Google Drive (read access)

The Google Drive MCP connector is available for reading existing documents from Drive -- no setup needed. Skills can search and pull documents from the team's Shared Drive automatically.

Confirm the connector is working by running a quick test search against Google Drive. If it returns results, note it as connected in the config.

**Note on intelligence sharing (future):** For the POC, intelligence files stay in the local intelligence/ folder. Syncing intelligence files to the team's Shared Drive (Nansen > nansen-cowork > intelligence) is a priority item for Phase 2. The approach for sharing extracted knowledge across the team is still being worked out. For now, focus on proving the extraction pipeline works.

## Step 4 -- Fathom connection

Fathom (https://fathom.video) records and transcribes meetings. The nansen-core plugin includes a remote Fathom MCP server hosted on Cloudflare Workers that provides `list_meetings`, `get_transcript`, and `get_meeting_details` tools. The server is already configured in the plugin's `.mcp.json` -- the only thing needed from the user is their Fathom API key.

**No local installation is required.** No Node.js, no npm, no terminal commands. The server runs in the cloud and the plugin connects to it automatically.

### Collect the API key

**Always explicitly ask the user for their Fathom API key.** Don't skip this silently -- prompt them directly and give them the option to enter it now or skip.

Say something like: "Next I need to connect Fathom so we can pull your meeting transcripts automatically. Do you have your Fathom API key handy? If not, here's how to get one -- it only takes a minute."

Then show them the steps:

1. Log into Fathom at https://fathom.video
2. Go to **Settings** (top right corner)
3. Scroll down to the **My Settings** section and find **API Access**
4. Click **Add**, then **Generate API Key**
5. Give the key a name (e.g., "Nansen Intelligence")
6. Click **Create API Client**
7. Copy the API key that appears

Then ask: "Paste your API key here when you're ready, or type 'skip' if you'd like to set this up later."

Note: Fathom API keys are user-level, which means each person's key only gives access to meetings they recorded or that were shared to their team. Each pilot member will need to generate their own key.

### If they provide a key

Save it as an environment variable so the plugin can use it automatically on future sessions:

```bash
# Add to ~/.zshrc (or ~/.bashrc for bash users)
echo 'export FATHOM_API_KEY="their-key-here"' >> ~/.zshrc
```

Tell the user: "I've saved your Fathom API key. You'll need to start a new Cowork session for it to take effect, but from then on Fathom will connect automatically every time."

Store in config: `fathom_connected: true, api_key_set: true`

### If they skip

That's fine -- let them know they can always drop transcript files into sources/ manually, and they can re-run /setup later to add the key.

Store in config: `fathom_connected: false, api_key_set: false`

## Step 5 -- Slack verification

Check if the Slack MCP connector is available by looking at the current conversation context. The Slack connector should already be set up in Cowork.

If Slack is available:
- Run a quick test search to confirm it's working
- Note: "Slack is connected. Skills can search your Slack workspace for relevant messages and threads."

If Slack doesn't appear to be connected:
- Explain: "The Slack connector lets skills search your workspace for relevant context. You can set it up in Cowork's connector settings."
- This is optional for POC -- note in config and move on

## Step 6 -- Generate config file

Create `.nansen-config.json` in the workspace root with the collected information:

```json
{
  "version": "1.0.0",
  "setup_date": "[ISO-8601 timestamp]",
  "setup_by": "[user name from conversation]",
  "workspace_paths": {
    "sources": "[absolute path to sources/]",
    "intelligence": "[absolute path to intelligence/]",
    "outputs": "[absolute path to outputs/]"
  },
  "google_drive": {
    "installed": true/false,
    "mount_path": "[detected path or null]",
    "shared_drive_folder": "[user-specified or null]",
    "sync_configured": true/false
  },
  "fathom": {
    "connected": true/false,
    "api_key_set": true/false
  },
  "slack": {
    "mcp_connected": true/false
  },
  "pilot_group": true
}
```

Write this file and confirm: "Your config is saved. Here's a summary of your setup."

## Step 7 -- Verification diagnostic

Run a quick health check to make sure everything is working:

1. **Folder check**: Verify all three directories exist and are writable
2. **Write test**: Create a small test file in intelligence/ called `_setup-verification.intelligence.md` with proper YAML frontmatter:

```markdown
---
title: Setup Verification Test
date: [today's date]
source_type: document
domains:
  - team-insights
version: 1
updated: [ISO-8601 now]
updated_by: nansen-core setup
---

# Setup Verification

This file was created by the /setup command to verify the intelligence pipeline is working correctly. You can safely delete this file.

Setup completed on [date] by [user name].
```

3. **Config check**: Read back the config file and confirm it's valid JSON
4. **Fathom check**: If the user provided an API key in Step 4, note PASS (key saved, will connect on next session). If they skipped, note SKIPPED. No server verification needed here -- the remote server is always running.
5. **Drive sync note**: If Drive is configured, remind the user to check that the test file appears in their Shared Drive within a minute or two

Present results as a checklist:
- Folder structure: PASS/FAIL
- Intelligence file creation: PASS/FAIL
- Config file: PASS/FAIL
- Fathom MCP server: PASS/FAIL/SKIPPED
- Google Drive: CONFIGURED/SKIPPED
- Fathom API key: CONNECTED/SKIPPED
- Slack: CONNECTED/SKIPPED

## Step 8 -- Configure Slack channels for sync

If Slack is connected (confirmed in Step 5), set up which channels the daily sync should monitor.

Use `slack_search_channels` to find channels the user is active in. Present a list showing the channel name, purpose/topic, and member count where available.

Say something like: "I can automatically pull intelligence from your Slack channels every day. Which channels should I monitor? These are your active channels -- pick the ones where business discussions happen."

Let the user select channels from the list (they can also type channel names). For each selected channel, store the `channel_id` and `channel_name` in the config under `sync.slack.channels[]`.

Recommend they include channels where:
- Client discussions happen
- Strategy and planning conversations occur
- Business development threads appear
- Project updates are shared

Recommend they exclude:
- Social/random channels
- Channels that are purely automated notifications
- Very high-volume channels that are mostly noise

Save the selections to the config. If no channels are selected, note that Slack sync will be skipped in the daily task but can be configured later.

If Slack is not connected, skip this step entirely.

## Step 9 -- Initial intelligence pull

Now that connectors are configured and channels are selected, run the first sync to give the user a baseline of intelligence.

Tell the user: "I'm going to pull the past week of content from your connected sources to build your baseline intelligence. This might take a few minutes depending on how active your Slack and Fathom have been."

Invoke the sync skill in initial mode:
- Read and follow `nansen-core/skills/sync/SKILL.md`
- Set the lookback window to 7 days
- Process all configured channels and any Fathom meetings from the past week
- Run the full filtering and extraction pipeline

When complete, share the summary report from the sync skill. Highlight a few of the intelligence files that were created so the user can see the value immediately.

If no content was found (no Slack messages, no Fathom meetings in the past week), that's fine. Tell the user: "No recent content found to sync, but you're all set. The daily sync will start picking things up from tomorrow."

## Step 10 -- Create daily sync task

Set up the recurring scheduled task that will run every morning.

Ask the user: "What time would you like the daily intelligence sync to run? This pulls new content from Slack and Fathom, filters for the important stuff, and creates intelligence files. Most people set it for sometime before they start work."

Wait for the user to specify a time.

Once they choose a time, create the scheduled task:

1. Read the sync prompt template from `nansen-core/templates/sync-prompt-template.md`
2. Expand the template variables with actual values from the config:
   - Replace `{{WORKSPACE_ROOT}}` with the actual workspace root path
   - Replace `{{SOURCES_PATH}}` with the actual sources path
   - Replace `{{INTELLIGENCE_PATH}}` with the actual intelligence path
   - Replace `{{SLACK_CHANNELS_JSON}}` with the JSON array from `sync.slack.channels`
   - Replace `{{PREFERRED_TIME}}` with the user's chosen time
   - Replace `{{SCHEMA_PATH}}` with the actual path to intelligence-schema.yaml
3. Call `create_scheduled_task` with:
   - `taskId`: "nansen-daily-sync"
   - `cronExpression`: Convert the user's time to cron format. For weekdays only use `M H * * 1-5`. For every day use `M H * * *`. Default to weekdays unless the user says otherwise.
   - `prompt`: The expanded template (everything after "Expanded Prompt" in the template)
   - `description`: "Daily intelligence sync - pulls Slack and Fathom content, extracts intelligence"
4. Save the task ID to `sync.scheduled_task_id` in the config
5. Save the preferred time to `sync.preferred_time` in the config

Confirm: "Your daily intelligence sync is set for [time] on weekdays. Each morning it will pull new content from your connected sources, filter for the important stuff, and create intelligence files. You'll see a summary when it runs."

## Wrap up

End with next steps:
- "You're all set! Here's what you can do next:"
- "Run `/onboarding` for a guided tour of how everything works"
- "Drop a PDF or transcript into sources/ and ask me to extract intelligence from it"
- "Ask me to run the Market Research skill on any source file"
- "Your daily sync runs at [time] -- check your intelligence/ folder tomorrow morning for fresh insights"
- "Want to change which Slack channels are monitored? Just ask me to update the sync config."
